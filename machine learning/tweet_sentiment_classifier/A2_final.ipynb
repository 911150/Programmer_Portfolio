{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import data and inspect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Noah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.FacetGrid at 0x15ab32b63d0>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import functions as f\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',') # this should only be used for the submission\n",
    "\n",
    "#print(train_data.sentiment)\n",
    "cols = train_data.columns\n",
    "\n",
    "# Plot class distributions\n",
    "import seaborn as sns\n",
    "sns.displot([x[0] for x in train_data[['sentiment']].values], discrete=True, bins=3)\n",
    "\n",
    "# convert training data to numbers for future binarization\n",
    "#train_data['sentiment'] = train_data['sentiment'].replace(['positive', 'negative', #'neutral'], [1, -1, 0])\n",
    "\n",
    "# code to convert back to label\n",
    "#df[column] = df[column].replace([1, -1, 0], ['positive', 'negative', 'neutral'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distributions in Training set:  Counter({0: 12659, 1: 5428, -1: 3715})\n",
      "Number of samples in Kaggle Testing set:  6099\n",
      "\n",
      "Raw tweet example:  is anybody going to the radio station tomorrow to see shawn? me and my friend may go but we would like to make new friends/meet there (:\t\n",
      " with sentiment: (1)\n"
     ]
    }
   ],
   "source": [
    "# Extract raw training tweets from df\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "\n",
    "# Extract raw training sentiment data from df\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values] # y training data\n",
    "\n",
    "# Extract test tweets from test.csv/test_data df\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Class distributions in Training set: \", Counter(Y_train))\n",
    "print(\"Number of samples in Kaggle Testing set: \", len(X_test_raw))\n",
    "\n",
    "\n",
    "print(\"Raw tweet example: {}\\n with sentiment: ({})\".format(X_train_raw[1], Y_train[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned tweet example:\n",
      " anybodi go radio station tomorrow see shawn friend may go would like make new friend meet emojismil\n",
      "with sentiment: (1)\n"
     ]
    }
   ],
   "source": [
    "# Clean the training and test data\n",
    "# remove random stuff, remove stopwords, stem the word, etc...\n",
    "from functions import preprocess_tweets\n",
    "X_train_clean = [preprocess_tweets(tweet) for tweet in X_train_raw] # X training data\n",
    "\n",
    "# -> Kaggle Parts\n",
    "X_test_clean = [preprocess_tweets(tweet) for tweet in X_test_raw] # for final submission on kaggle\n",
    "# extract labels for future predictions\n",
    "Y_test_labels = [x[0] for x in test_data[['id']].values]\n",
    "# <- End Kaggle Parts\n",
    "\n",
    "print(\"Cleaned tweet example:\\n {}\\nwith sentiment: ({})\".format(X_train_clean[1], Y_train[1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "LR = LogisticRegression(random_state=1, C=1.0, max_iter=2000)\n",
    "RFC = RandomForestClassifier(random_state=1, criterion='gini', n_estimators=100)\n",
    "LSVC = LinearSVC(C=0.1)\n",
    "MNB = MultinomialNB(alpha=1)\n",
    "\n",
    "# TODO remove this f i dont use it\n",
    "LR_base = LogisticRegression(random_state=1, C=1.0, max_iter=2000)\n",
    "RFC_base = RandomForestClassifier(random_state=1, criterion='gini', n_estimators=100)\n",
    "LSVC_base = LinearSVC(C=0.1)\n",
    "MNB_base = MultinomialNB(alpha=1)\n",
    "\n",
    "estimators = [('lr',LR),\n",
    "              ('rf', RFC),\n",
    "              ('lsvc', LSVC),\n",
    "              ('mnb', MNB)]\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "ensemble_clf = VotingClassifier(estimators=estimators)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search for best parameters - performed using BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'lr__C': [1.0, 50.0, 100.0],\n",
    "           'lr__max_iter':[1000, 2000],\n",
    "           'rf__n_estimators': [20, 100],\n",
    "           'lsvc__C': [0.1, 0.5, 1],\n",
    "           'mnb__alpha': [0.00001, 1]}\n",
    "\n",
    "# Grid search the best parameters for the Majority Voting classifier\n",
    "#grid = GridSearchCV(estimator=ensemble_clf, param_grid=params, cv=2, scoring='accuracy'\n",
    "# verbose=3)\n",
    "#grid.fit(X_train_bow, Y_train)\n",
    "\n",
    "# print best params from grid search\n",
    "#grid.cv_results_['params'][grid.best_index_]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble/Stacking Method using BoW - No oversampling/undersampling - Scoring = Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Vectorize the training and test data using BoW approach\n",
    "vec_bow = CountVectorizer(ngram_range=(1, 2))\n",
    "vec_bow.fit(X_train_clean)\n",
    "X_train_bow = vec_bow.transform(X_train_clean)\n",
    "X_test_bow = vec_bow.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for clf, label in zip([ensemble_clf, stacking_clf], ['Majority Voting', 'Stacking']):\n",
    "#     scores =cross_val_score(clf, X_train_bow, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble/Stacking Method using Tfid - No oversampling/undersampling - Scoring = Accuracy #TODO remove this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Vectorize the training and test data\n",
    "vec_tfid = TfidfVectorizer(use_idf = True,\n",
    "                           ngram_range=(1, 2),\n",
    "                           sublinear_tf=True)\n",
    "\n",
    "vec_tfid.fit(X_train_clean)\n",
    "X_train_Tfid = vec_tfid.transform(X_train_clean)\n",
    "X_test_Tfid = vec_tfid.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for clf, label in zip([ensemble_clf, stacking_clf], ['Majority Voting', 'Stacking']):\n",
    "#     scores =cross_val_score(clf, X_train_Tfid, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid)\" % (scores.mean(), scores.std(), label))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers performance LR, RFC, LSVC, MNB - BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_bow, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW)\" % (scores.mean(), scores.std(), label))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers performance LR, RFC, LSVC, MNB - Tfid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_bow, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid)\" % (scores.mean(), scores.std(), label))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Undersample from the dataset's majority class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "# initialise undersampler\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "X_train_clean_reshape = pd.DataFrame(X_train_clean)\n",
    "\n",
    "# undersample the entire dataset\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train_clean_reshape, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='not majority')\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train_clean_reshape, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inspect\n",
    "#print(X_train_under.head)\n",
    "#print(y_train_under)\n",
    "\n",
    "# Plot distribution of undersampled data\n",
    "sns.displot([x for x in y_train_under], discrete=True, bins=3)\n",
    "# summarize class distribution\n",
    "print(\"Before undersampling: \", Counter(Y_train))\n",
    "print(\"After undersampling: \", Counter(y_train_under))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers, under-sampled, BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize the training and test data using BoW approach\n",
    "vec_bow_undersample = CountVectorizer(ngram_range=(1, 2))\n",
    "vec_bow_undersample.fit(X_train_under.stack())\n",
    "X_train_bow_undersample = vec_bow.transform(X_train_under.stack())\n",
    "#X_test_bow = vec_bow.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61 (+/- 0.01) [Random Forest Classifier] (BoW, Undersampling)\n",
      "Accuracy: 0.64 (+/- 0.01) [Logistic Regression] (BoW, Undersampling)\n",
      "Accuracy: 0.64 (+/- 0.01) [Linear SVM] (BoW, Undersampling)\n",
      "Accuracy: 0.62 (+/- 0.00) [Multinominal Naive Bayes] (BoW, Undersampling)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_bow_undersample, y_train_under, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW, Undersampling)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers, under-sampled, tfid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec_tfid_undersample = TfidfVectorizer(use_idf = True,\n",
    "                                      ngram_range=(1, 2),\n",
    "                                      sublinear_tf=True)\n",
    "vec_tfid_undersample.fit(X_train_under.stack())\n",
    "X_train_tfid_undersample = vec_tfid_undersample.transform(X_train_under.stack())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60 (+/- 0.00) [Random Forest Classifier] (Tfid, Undersampling)\n",
      "Accuracy: 0.63 (+/- 0.00) [Logistic Regression] (Tfid, Undersampling)\n",
      "Accuracy: 0.62 (+/- 0.00) [Linear SVM] (Tfid, Undersampling)\n",
      "Accuracy: 0.55 (+/- 0.00) [Multinominal Naive Bayes] (Tfid, Undersampling)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_tfid_undersample, y_train_under, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid, Undersampling)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the Kaggle dataset using Stacking Classifier + BoW + Undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try this out on the kaggle dataset\n",
    "stacking_clf.fit(X_train_bow_undersample, y_train_under)\n",
    "kaggle_submit_bow = stacking_clf.predict(X_test_bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a dummy classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58 (+/- 0.00) [Zero R] (Full dataset)\n",
      "Accuracy: 0.58 (+/- 0.00) [Zero R] (Full dataset)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(                                                       0\n 0      user user pay back senior citizen medicar serv...\n 1      stop post pictur januari charli hebdo attack t...\n 2      death death el go aleppo syria standwithaleppo...\n 3                                  user wait maduro turn\n 4      cheeto nazi mad fat as look like tub curdl ora...\n ...                                                  ...\n 12853  last minut anyon want go sam smith w tomorrow ...\n 12854  go red sox game tomorrow even though im yanke ...\n 12855  tonight user cape guest user jimmi second favo...\n 12856  paul dunn tie st open he proud uabblaz shutout...\n 12857  user use moto g nd gen month absolut delight s...\n \n [12858 rows x 1 columns],\n [-1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  ...])"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train_bow_undersample, y_train_under)\n",
    "\n",
    "dummy_scores = cross_val_score(dummy_clf, X_train_clean, Y_train, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Full dataset)\" % (dummy_scores.mean(), dummy_scores.std(), \"Zero R\"))\n",
    "\n",
    "dummy_scores_under = cross_val_score(dummy_clf, X_train_under, y_train_under, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Undersampled)\" % (dummy_scores.mean(), dummy_scores.std(), \"Zero R\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Output results to CSV for kaggle - undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oversampling code - didnt provide any useful discoveries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "X_train_clean_reshape = pd.DataFrame(X_train_clean)\n",
    "\n",
    "# oversample the entire dataset\n",
    "oversampler = RandomOverSampler(sampling_strategy='not majority')\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train_clean_reshape, Y_train)\n",
    "# inspect\n",
    "#print(X_train_over.head)\n",
    "#print(y_train_over)\n",
    "\n",
    "# Plot distribution of oversampled data\n",
    "sns.displot([x for x in y_train_over], discrete=True, bins=3)\n",
    "# summarize class distribution\n",
    "print(\"Before oversampling: \", Counter(Y_train))\n",
    "print(\"After oversampling: \", Counter(y_train_over))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize the training and test data using BoW approach\n",
    "vec_bow_oversample = CountVectorizer(ngram_range=(1, 2))\n",
    "vec_bow_oversample.fit(X_train_over.stack())\n",
    "X_train_bow_oversample = vec_bow.transform(X_train_over.stack())\n",
    "#X_test_bow = vec_bow.transform(X_test_clean)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf],\n",
    "                      ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes',\n",
    "                       'Majority Voting', 'Stacking']):\n",
    "    scores = cross_val_score(clf, X_train_bow_oversample, y_train_over, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW, Oversampling)\" % (scores.mean(), scores.std(), label))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec_tfid_oversample = TfidfVectorizer(use_idf=True,\n",
    "                                       ngram_range=(1, 2),\n",
    "                                       sublinear_tf=True)\n",
    "vec_tfid_oversample.fit(X_train_over.stack())\n",
    "X_train_tfid_oversample = vec_tfid_oversample.transform(X_train_over.stack())\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf],\n",
    "                      ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes',\n",
    "                       'Majority Voting', 'Stacking']):\n",
    "    scores = cross_val_score(clf, X_train_tfid_oversample, y_train_over, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid, Oversampling)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}