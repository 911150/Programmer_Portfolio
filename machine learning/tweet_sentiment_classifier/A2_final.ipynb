{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/noahs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# modelling\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# udf\n",
    "from functions import preprocess_tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise and inspect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "# read in data\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',') # this should only be used for the submission\n",
    "cols = train_data.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.FacetGrid at 0x7f0dc92e6640>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot class distributions\n",
    "sns.displot([x[0] for x in train_data[['sentiment']].values], discrete=True, bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distributions in Training set:  Counter({'neutral': 12659, 'positive': 5428, 'negative': 3715})\n",
      "Number of samples in Kaggle Testing set:  6099\n",
      "Raw tweet example:  is anybody going to the radio station tomorrow to see shawn? me and my friend may go but we would like to make new friends/meet there (:\t\n",
      " with sentiment: (positive)\n"
     ]
    }
   ],
   "source": [
    "# Extract raw training tweets from df\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "\n",
    "# Extract raw training sentiment data from df\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values] # y training data\n",
    "\n",
    "# Extract test tweets from test.csv/test_data df\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "\n",
    "print(\"Class distributions in Training set: \", Counter(Y_train))\n",
    "print(\"Number of samples in Kaggle Testing set: \", len(X_test_raw))\n",
    "print(\"Raw tweet example: {}\\n with sentiment: ({})\".format(X_train_raw[1], Y_train[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned tweet example:\n",
      " anybodi go radio station tomorrow see shawn friend may go would like make new friend meet emojismil\n",
      "with sentiment: (positive)\n"
     ]
    }
   ],
   "source": [
    "# Clean the training and test data\n",
    "X_train_clean = [preprocess_tweets(tweet) for tweet in X_train_raw] # X training data\n",
    "\n",
    "# -> Kaggle Parts\n",
    "X_test_clean = [preprocess_tweets(tweet) for tweet in X_test_raw] # for final submission on kaggle\n",
    "# extract labels for future predictions\n",
    "Y_test_labels = [x[0] for x in test_data[['id']].values]\n",
    "# <- End Kaggle Parts\n",
    "\n",
    "# inspect a cleaned tweet\n",
    "print(\"Cleaned tweet example:\\n {}\\nwith sentiment: ({})\".format(X_train_clean[1], Y_train[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise Classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=1, C=1.0, max_iter=2000)\n",
    "RFC = RandomForestClassifier(random_state=1, criterion='gini', n_estimators=100)\n",
    "LSVC = LinearSVC(C=0.1)\n",
    "MNB = MultinomialNB(alpha=1)\n",
    "\n",
    "# TODO: remove this f i dont use it\n",
    "LR_base = LogisticRegression(random_state=1, C=1.0, max_iter=2000)\n",
    "RFC_base = RandomForestClassifier(random_state=1, criterion='gini', n_estimators=100)\n",
    "LSVC_base = LinearSVC(C=0.1)\n",
    "MNB_base = MultinomialNB(alpha=1)\n",
    "\n",
    "estimators = [('lr',LR),\n",
    "              ('rf', RFC),\n",
    "              ('lsvc', LSVC),\n",
    "              ('mnb', MNB)]\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "ensemble_clf = VotingClassifier(estimators=estimators)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search for best parameters - performed using BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "# params = {'lr__C': [1.0, 50.0, 100.0],\n",
    "#            'lr__max_iter':[1000, 2000],\n",
    "#            'rf__n_estimators': [20, 100],\n",
    "#            'lsvc__C': [0.1, 0.5, 1],\n",
    "#            'mnb__alpha': [0.00001, 1]}\n",
    "#\n",
    "# # grid search the best parameters for the Majority Voting classifier\n",
    "# grid = GridSearchCV(estimator=ensemble_clf, param_grid=params, cv=2, scoring='accuracy'\n",
    "# verbose=3)\n",
    "# grid.fit(X_train_bow, Y_train)\n",
    "#\n",
    "# # print best params from grid search\n",
    "# grid.cv_results_['params'][grid.best_index_]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble/Stacking Method using BoW - No oversampling/undersampling - Scoring = Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Vectorize the training and test data using BoW approach\n",
    "vec_bow = CountVectorizer(ngram_range=(1, 2))\n",
    "vec_bow.fit(X_train_clean)\n",
    "X_train_bow = vec_bow.transform(X_train_clean)\n",
    "X_test_bow = vec_bow.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# for clf, label in zip([ensemble_clf, stacking_clf], ['Majority Voting', 'Stacking']):\n",
    "#     scores =cross_val_score(clf, X_train_bow, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble/Stacking Method using Tfid - No oversampling/undersampling - Scoring = Accuracy #TODO remove this"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Vectorize the training and test data\n",
    "vec_tfid = TfidfVectorizer(use_idf = True,\n",
    "                           ngram_range=(1, 2),\n",
    "                           sublinear_tf=True)\n",
    "\n",
    "vec_tfid.fit(X_train_clean)\n",
    "X_train_Tfid = vec_tfid.transform(X_train_clean)\n",
    "X_test_Tfid = vec_tfid.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# for clf, label in zip([ensemble_clf, stacking_clf], ['Majority Voting', 'Stacking']):\n",
    "#     scores =cross_val_score(clf, X_train_Tfid, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers performance LR, RFC, LSVC, MNB - BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63 (+/- 0.00) [Random Forest Classifier] (BoW)\n",
      "Accuracy: 0.65 (+/- 0.01) [Logistic Regression] (BoW)\n",
      "Accuracy: 0.65 (+/- 0.01) [Linear SVM] (BoW)\n",
      "Accuracy: 0.63 (+/- 0.00) [Multinominal Naive Bayes] (BoW)\n",
      "Accuracy: 0.65 (+/- 0.01) [Majority Voting] (BoW)\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_bow, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers performance LR, RFC, LSVC, MNB - Tfid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_bow, Y_train, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Undersample from the dataset's majority class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reshape to fix index\n",
    "X_train_clean_reshape = pd.DataFrame(X_train_clean)\n",
    "\n",
    "# under-sample the dataset\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train_clean_reshape, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# over-sample the dataset\n",
    "oversampler = RandomOverSampler(sampling_strategy='not majority')\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train_clean_reshape, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inspect numerically\n",
    "#print(X_train_under.head)\n",
    "#print(y_train_under)\n",
    "\n",
    "# Plot distribution of under-sampled data\n",
    "sns.displot([x for x in y_train_under], discrete=True, bins=3)\n",
    "\n",
    "# summarize class distribution\n",
    "print(\"Before undersampling: \", Counter(Y_train))\n",
    "print(\"After undersampling: \", Counter(y_train_under))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers, under-sampled, BoW"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Vectorize the training and test data using BoW approach\n",
    "vec_bow_undersample = CountVectorizer(ngram_range=(1, 2))\n",
    "vec_bow_undersample.fit(X_train_under.stack())\n",
    "X_train_bow_undersample = vec_bow.transform(X_train_under.stack())\n",
    "#X_test_bow = vec_bow.transform(X_test_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_bow_undersample, y_train_under, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW, Undersampling)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Accuracy scores for classifiers, under-sampled, tfid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Vectorize using Term-Frequency-Inverse-Document-Frequency approach\n",
    "vec_tfid_undersample = TfidfVectorizer(use_idf = True,\n",
    "                                      ngram_range=(1, 2),\n",
    "                                      sublinear_tf=True)\n",
    "vec_tfid_undersample.fit(X_train_under.stack())\n",
    "X_train_tfid_undersample = vec_tfid_undersample.transform(X_train_under.stack())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf], ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes', 'Majority Voting', 'Stacking']):\n",
    "    scores =cross_val_score(clf, X_train_tfid_undersample, y_train_under, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid, Undersampling)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the Kaggle dataset using Stacking Classifier + BoW + Undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Try this out on the kaggle dataset\n",
    "stacking_clf.fit(X_train_bow_undersample, y_train_under)\n",
    "kaggle_submit_bow = stacking_clf.predict(X_test_bow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a dummy classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train_bow_undersample, y_train_under)\n",
    "\n",
    "dummy_scores = cross_val_score(dummy_clf, X_train_clean, Y_train, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Full dataset)\" % (dummy_scores.mean(), dummy_scores.std(), \"Zero R\"))\n",
    "\n",
    "dummy_scores_under = cross_val_score(dummy_clf, X_train_under, y_train_under, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Undersampled)\" % (dummy_scores.mean(), dummy_scores.std(), \"Zero R\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Output results to CSV for kaggle - undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oversampling code - didnt provide any useful discoveries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "X_train_clean_reshape = pd.DataFrame(X_train_clean)\n",
    "\n",
    "# oversample the entire dataset\n",
    "oversampler = RandomOverSampler(sampling_strategy='not majority')\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train_clean_reshape, Y_train)\n",
    "# inspect\n",
    "#print(X_train_over.head)\n",
    "#print(y_train_over)\n",
    "\n",
    "# Plot distribution of oversampled data\n",
    "sns.displot([x for x in y_train_over], discrete=True, bins=3)\n",
    "# summarize class distribution\n",
    "print(\"Before oversampling: \", Counter(Y_train))\n",
    "print(\"After oversampling: \", Counter(y_train_over))\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vectorize the training and test data using BoW approach\n",
    "vec_bow_oversample = CountVectorizer(ngram_range=(1, 2))\n",
    "vec_bow_oversample.fit(X_train_over.stack())\n",
    "X_train_bow_oversample = vec_bow.transform(X_train_over.stack())\n",
    "#X_test_bow = vec_bow.transform(X_test_clean)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf],\n",
    "                      ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes',\n",
    "                       'Majority Voting', 'Stacking']):\n",
    "    scores = cross_val_score(clf, X_train_bow_oversample, y_train_over, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (BoW, Oversampling)\" % (scores.mean(), scores.std(), label))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec_tfid_oversample = TfidfVectorizer(use_idf=True,\n",
    "                                       ngram_range=(1, 2),\n",
    "                                       sublinear_tf=True)\n",
    "vec_tfid_oversample.fit(X_train_over.stack())\n",
    "X_train_tfid_oversample = vec_tfid_oversample.transform(X_train_over.stack())\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf, label in zip([RFC, LR, LSVC, MNB, ensemble_clf, stacking_clf],\n",
    "                      ['Random Forest Classifier', 'Logistic Regression', 'Linear SVM', 'Multinominal Naive Bayes',\n",
    "                       'Majority Voting', 'Stacking']):\n",
    "    scores = cross_val_score(clf, X_train_tfid_oversample, y_train_over, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s] (Tfid, Oversampling)\" % (scores.mean(), scores.std(), label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}