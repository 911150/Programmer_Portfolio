{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/22 16:29:59 WARN Utils: Your hostname, LAPTOP-VAB0S7AL resolves to a loopback address: 127.0.1.1; using 172.27.239.27 instead (on interface eth0)\n",
      "22/08/22 16:29:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/noahs/miniconda3/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/08/22 16:30:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/08/22 16:30:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from _global_vars import *\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034_Yellow_Taxi_Preprocessing_Cleaning\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read in feature engineered and collated 2019 taxi data & confirm\n",
    "sdf = spark.read.parquet('../data/curated/yt2019_feature_eng.parquet')\n",
    "#sdf.show(1, vertical=True, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84180903"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_records = sdf.count()\n",
    "#print(total_records)\n",
    "sdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Remove bad records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Filters (collated from univariate analysis)\n",
    "* Restrict range of passenger_count (1:6) [drop other records]\n",
    "* Only take 312miles > trip distances > 0 (3 hours at maximum speed)\n",
    "* Fares capped at $500 (0:500)\n",
    "* remove trips with average speed over 104 mph and remove trips less than 1 mph\n",
    "* Limit trip times to under 5 hours (300 minutes) (more than it takes to drive entire perimeter of nyc)\n",
    "* Trips with a time of less than 2 minutes should be excluded => not very realistic => passenger may have cancelled\n",
    "* Congestion surcharge capped at 10 usd -> any records beyond this can go away\n",
    "* Ratecode == 1 and fare < 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from clean import get_outliers_df, remove_outliers\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "outlier_df = get_outliers_df(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0  prop_of_total\n",
      "congestion        5415432       0.064331\n",
      "ratecode_min_fee  3581882       0.042550\n",
      "t_time            2093024       0.024863\n",
      "passenger_count   1960201       0.023286\n",
      "t_speed           1093001       0.012984\n",
      "pay_type          1071550       0.012729\n",
      "DOLocation         984803       0.011699\n",
      "PULocationID       830761       0.009869\n",
      "trip_distance      748600       0.008893\n",
      "rcode_id           444867       0.005285\n",
      "vendorid           267050       0.003172\n",
      "fare_amount        204131       0.002425\n",
      "tip_amount           1827       0.000022\n"
     ]
    }
   ],
   "source": [
    "print(outlier_df.sort_values('prop_of_total', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sdf = remove_outliers(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|is_valid_record|   count|\n",
      "+---------------+--------+\n",
      "|           true|71742914|\n",
      "|          false|12437989|\n",
      "+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.groupBy(\"is_valid_record\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71742914"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove bad records\n",
    "sdf_filtered = sdf.filter(sdf.is_valid_record == True)\n",
    "sdf_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:=====================================================>  (22 + 1) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------------+--------------------+\n",
      "|summary|     trip_distance|        tip_amount|   passenger_count|      fare_amount|congestion_surcharge|\n",
      "+-------+------------------+------------------+------------------+-----------------+--------------------+\n",
      "|  count|          71742914|          71742914|          71742914|         71742914|            71742914|\n",
      "|   mean| 2.589011225415214|2.0483753208021587|1.5949647654401102|11.92635378819433|  2.2415673274715324|\n",
      "| stddev|2.8274863324423087|2.1991967369536964| 1.203682438758781|8.348539350425064|  0.7611033913076103|\n",
      "|    min|              0.04|               0.0|               1.0|              2.5|                 0.0|\n",
      "|    max|             149.5|             500.0|               6.0|            394.5|                2.75|\n",
      "+-------+------------------+------------------+------------------+-----------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# looks much nicer if you ask me...\n",
    "summary_stats_continuous = sdf_filtered.describe(*non_categorical_features)\n",
    "summary_stats_continuous.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'congestion_surcharge',\n",
       " 'PU_hourofday',\n",
       " 'DO_hourofday',\n",
       " 'PU_dayofweek',\n",
       " 'DO_dayofweek',\n",
       " 'PU_dayofmonth',\n",
       " 'DO_dayofmonth',\n",
       " 'PU_month',\n",
       " 'DO_month',\n",
       " 'trip_time_minutes',\n",
       " 'trip_speed_mph',\n",
       " 'fare_per_minute',\n",
       " 'tmpf',\n",
       " 'dwpf',\n",
       " 'relh']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depr_features = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'tip_amount','PU_datetime', 'DO_datetime', 'hour_of_day_of_year', 'is_valid_record']\n",
    "sdf_filtered = sdf_filtered.drop(*depr_features)\n",
    "sdf_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "export_relative_dir = '../data/curated/'\n",
    "sdf_filtered.write.mode('overwrite').parquet(export_relative_dir + \"yt2019_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# looks much nicer if you ask me...\n",
    "sdf_filtered.describe(*non_categorical_features).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"CLEAR CACHE\")\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}